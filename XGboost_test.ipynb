{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Challenge - Traffic Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook preprocesses the test dataset and load the pretrained XGBoost model to predict traffic demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split timestamp to hour and minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['timestamp'].apply(lambda x: int(x.split(':')[0]))\n",
    "df['minute'] = df['timestamp'].apply(lambda x: int(x.split(':')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert geohash to latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohash2LatLong(gh):\n",
    "    lat_long = geohash.decode_exactly(gh)\n",
    "    return float(lat_long[0]), float(lat_long[1])\n",
    "\n",
    "lats = []\n",
    "longs = []\n",
    "for index, row in df.iterrows():\n",
    "    lat, long = geohash2LatLong(row['geohash6'])\n",
    "    lats.append(lat)\n",
    "    longs.append(long)\n",
    "\n",
    "df['lat'] = lats\n",
    "df['long'] = longs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Feature 1: Past Days Demand Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature looks up the previous demand values of each geohash location for past few days. This is to incorporate time-series feature of the dataset into the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of past days to look up as feature\n",
    "no_days_lookup = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_mean = df.groupby(['geohash6', 'day'])['demand'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert additional feature columns\n",
    "for i in range(no_days_lookup):\n",
    "    column = 'D-' + str(i+1) + ' mean'\n",
    "    df.insert(len(df.columns), column, value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Han\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "#     print(i)\n",
    "    geohash_value = row['geohash6']\n",
    "    day = row['day']\n",
    "    for j in range(no_days_lookup):\n",
    "        column = 'D-' + str(j+1) + ' mean'\n",
    "        insert_tuple = (geohash_value, day-(j+1))\n",
    "        if insert_tuple in day_mean.index:\n",
    "            df.set_value(i, column, float(day_mean.loc[[insert_tuple]]))\n",
    "        else:\n",
    "            df.set_value(i, column, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Feature 2: Nearest Neighbours Demand Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature uses Spotify's Annoy library to find the nearest neighbours of each data entries at given timeframe, and uses product of neighbours demand value and distance to the neigbhour as the additional feature to incorporate spatial element to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of closest neighbours to use as feature\n",
    "no_neighbours = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe to find nearest neighbours in each day and time\n",
    "df = df.sort_values(by=['day', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert additional feature columns\n",
    "for i in range(no_neighbours):\n",
    "    column = str(i+1) + '_neighbour'\n",
    "    df.insert(len(df.columns), column, value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in same timeframe (date and time) belongs to the same 'window'\n",
    "\n",
    "windows = []\n",
    "window_indices = []\n",
    "day = None\n",
    "timestamp = None\n",
    "for i, row in df.iterrows():\n",
    "    if day == None and timestamp == None:\n",
    "        day = row['day']\n",
    "        timestamp = row['timestamp']\n",
    "    elif row['day'] != day or row['timestamp'] != timestamp:\n",
    "        windows.append(window_indices)\n",
    "        window_indices = []\n",
    "        day = None\n",
    "        timestamp = None\n",
    "    window_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Han\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Insert (demand * distance) value of nearest neighbours into dataframe \n",
    "\n",
    "for window in windows:\n",
    "    t = AnnoyIndex(2, metric='euclidean')\n",
    "    for index in window:\n",
    "        t.add_item(index, [df['lat'][index], df['long'][index]])\n",
    "    t.build(10)\n",
    "    \n",
    "    for index in window:\n",
    "        indices, distances = t.get_nns_by_item(i=index, n=no_neighbours+1, include_distances=True)\n",
    "        neighbours = list(zip(indices, distances))[1:] # Exclusde first neighbour => itself\n",
    "        for i, neighbour in enumerate(neighbours):\n",
    "            neighbour_index = neighbour[0]\n",
    "            neighbour_distance = neighbour[1]\n",
    "            neighbour_demand = df['demand'][neighbour_index]\n",
    "            column = str(i+1) + '_neighbour'\n",
    "            df[column][index] = neighbour_distance * neighbour_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshuffle dataframe\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pretrained XGBoost Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:52:30] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open(\"traffic_xgboost.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['demand']\n",
    "X = df.drop(['geohash6', 'timestamp', 'demand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction\n",
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.132396\n"
     ]
    }
   ],
   "source": [
    "# Calculate Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
